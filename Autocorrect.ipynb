{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOuyZio78FAM",
        "outputId": "df1f0702-e985-4143-970d-f122ca0bd59d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 3 words similar to 'tochter' are: ['tocher', 'toucher', 'torcher']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import words\n",
        "import heapq\n",
        "\n",
        "nltk.download('words')\n",
        "\n",
        "# Function to calculate similarity\n",
        "def similarity(word1, word2):\n",
        "    word1, word2 = word1.lower(), word2.lower()\n",
        "    similarity = 0  # Higher means more similar\n",
        "    positions = {}\n",
        "\n",
        "    for idx, char in enumerate(word2):\n",
        "        if char not in positions:\n",
        "            positions[char] = []\n",
        "        positions[char].append(idx)\n",
        "\n",
        "    for idx1, char1 in enumerate(word1):\n",
        "        if char1 in positions:\n",
        "            closest = min(positions[char1], key=lambda x: abs(x - idx1))\n",
        "            difference = abs(closest - idx1)\n",
        "            score = 1 - (difference / len(word1))\n",
        "            similarity += score\n",
        "            positions[char1].remove(closest)\n",
        "            if not positions[char1]:\n",
        "                del positions[char1]\n",
        "\n",
        "    normalized_similarity = similarity / max(len(word2), len(word1))\n",
        "    return normalized_similarity\n",
        "\n",
        "def top_n_similar(new_word, n=3):\n",
        "    word_list = words.words()\n",
        "    heap = []\n",
        "    for word in word_list:\n",
        "        score = similarity(new_word, word)\n",
        "        if len(heap) < n:\n",
        "            heapq.heappush(heap, (score, word))\n",
        "        else:\n",
        "            heapq.heappushpop(heap, (score, word))\n",
        "    return [word for score, word in sorted(heap, reverse=True)]\n",
        "\n",
        "# Example usage\n",
        "new_word = \"tochter\"\n",
        "top_similar_words = top_n_similar(new_word)\n",
        "print(f\"The top {len(top_similar_words)} words similar to '{new_word}' are: {top_similar_words}\")\n"
      ]
    }
  ]
}